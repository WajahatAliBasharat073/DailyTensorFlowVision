{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Algebra Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[ 66,  72,  78],\n",
       "       [156, 171, 186]], dtype=int32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=tf.constant([[1,2,3],[4,5,6]])\n",
    "b=tf.constant([[7,8,9],[10,11,12],[13,14,15]])\n",
    "MLAs=tf.linalg.matmul(\n",
    "    a,\n",
    "    b,\n",
    "    transpose_a=False,\n",
    "    transpose_b=False,\n",
    "    adjoint_a=False,\n",
    "    adjoint_b=False,\n",
    "    a_is_sparse=False,\n",
    "    b_is_sparse=False,\n",
    "    output_type=None,\n",
    "    grad_a=False,\n",
    "    grad_b=False,\n",
    "    name=None\n",
    ")\n",
    "MLAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[ 66,  72,  78],\n",
       "       [156, 171, 186]], dtype=int32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a@b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[ 66, 156],\n",
       "       [ 72, 171],\n",
       "       [ 78, 186]], dtype=int32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(MLAs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 749  817  885]\n",
      "  [1412 1567 1722]]\n",
      "\n",
      " [[1281 1428 1575]\n",
      "  [ 853  953 1053]]\n",
      "\n",
      " [[ 204  222  240]\n",
      "  [ 415  455  495]]], shape=(3, 2, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[ 749  817  885]\n",
      "  [1412 1567 1722]]\n",
      "\n",
      " [[1281 1428 1575]\n",
      "  [ 853  953 1053]]\n",
      "\n",
      " [[ 204  222  240]\n",
      "  [ 415  455  495]]], shape=(3, 2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "## 3D matrix multiplication\n",
    "## several two-d  tensors  combine to  form three-d tensors\n",
    "a=tf.constant([\n",
    "    [[1,2,3],\n",
    "     [6,7,8]],\n",
    "    [[6,8,1],\n",
    "     [7,7,2]]\n",
    "]\n",
    ")\n",
    "a=tf.constant([\n",
    "    [[11,23,34],\n",
    "     [64,73,18]],\n",
    "    [[64,82,1],\n",
    "     [71,7,22]],\n",
    "    [[4,2,12],\n",
    "     [17,1,22]],\n",
    "]\n",
    ")\n",
    "print(a@b)\n",
    "threeD=tf.linalg.matmul(\n",
    "    a,\n",
    "    b,\n",
    "    transpose_a=False,\n",
    "    transpose_b=False,\n",
    "    adjoint_a=False,\n",
    "    adjoint_b=False,\n",
    "    a_is_sparse=False,\n",
    "    b_is_sparse=False,\n",
    "    output_type=None,\n",
    "    grad_a=False,\n",
    "    grad_b=False,\n",
    "    name=None\n",
    ")\n",
    "print(threeD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- band_part\n",
    "  (copy  a tensor setting everything outside a central band  in each innermost matrix to zero.)\n",
    "  -  tf.linalg.band_part(input, 0, -1) ==> Upper triangular part.\n",
    "  -  tf.linalg.band_part(input, -1, 0) ==> Lower triangular part.\n",
    "  -   tf.linalg.band_part(input, 0, 0) ==> Diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 0 0]\n",
      " [0 9 0]\n",
      " [0 0 0]], shape=(3, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 0  1  2]\n",
      " [-1  9  1]\n",
      " [ 0 -1  0]], shape=(3, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 0  1  0]\n",
      " [-1  9  1]\n",
      " [-2 -1  0]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# in_band(m, n) = (num_lower < 0 || (m-n) <= num_lower)) && (num_upper < 0 || (n-m) <= num_upper)\n",
    "input=tf.constant([[ 0,  1,  2],\n",
    "               [-1,  9,  1],\n",
    "               [-2, -1,  0]])\n",
    "\n",
    "lower = 1\n",
    "upper = -1\n",
    "m =0\n",
    "n= 1\n",
    "\n",
    "# ((m-n) <= num_lower)) && ((n-m) <= num_upper)\n",
    "print(tf.linalg.band_part(input, 0, 0))\n",
    "# [[0, 0, 0],\n",
    "# [0, 9, 0]\n",
    "# [0, 0, 0]]\n",
    "\n",
    "\n",
    "print(tf.linalg.band_part(input, 1, -1))\n",
    "# [[0, 0, 0],\n",
    "#  [-1, 0, 0],\n",
    "#  [0, -1, 0]]\n",
    "\n",
    "print(tf.linalg.band_part(input, 2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most useful Remaining functions below\n",
    "- cholesky\n",
    "- cross \n",
    "- det\n",
    "- inverse ( rows should be equal to columns)\n",
    "- svd\n",
    "- trace\n",
    "- einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([9.2274275 2.092185  1.8647555], shape=(3,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.13652577  0.02242501  0.99038285]\n",
      " [ 0.9867304  -0.09177202 -0.13394435]\n",
      " [-0.08788571 -0.9955276   0.03465671]], shape=(3, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.08788569  0.9955275   0.03465896]\n",
      " [ 0.98673034  0.0917723  -0.13394411]\n",
      " [ 0.13652578 -0.0224273   0.9903827 ]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input=tf.constant([[0,  1,  2],\n",
    "             [-1,  9,  1],\n",
    "             [-2, -1,  0]], dtype=float)\n",
    "s,u,v=tf.linalg.svd(input)\n",
    "print(s)\n",
    "print(u)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### einsum output\n",
    "ij X jk = ik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n",
      "(4, 5)\n",
      "[[ 179  198  217  240 1891]\n",
      " [  90  100  110  122 1117]\n",
      " [ 174  196  218  248 2260]]\n",
      "\n",
      "\n",
      "[[ 179  198  217  240 1891]\n",
      " [  90  100  110  122 1117]\n",
      " [ 174  196  218  248 2260]]\n"
     ]
    }
   ],
   "source": [
    "A= np.array([[2,3,5,9],\n",
    "             [1,2,3,4],\n",
    "             [4,5,6,7]])\n",
    "print(A.shape)\n",
    "B= np.array([[1,2,3,6,12],\n",
    "             [5,6,7,8,15],\n",
    "             [9,10,11,12,341],\n",
    "             [13,14,15,16,13]])\n",
    "print(B.shape)\n",
    "print(np.matmul(A, B))\n",
    "print()\n",
    "print()\n",
    "print(np.einsum(\"ij,jk->ik\",A, B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "[ 7 10 14 20]\n",
      "[19 10 22]\n"
     ]
    }
   ],
   "source": [
    "## just suming all the elements\n",
    "A = np.array([[2, 3, 5, 9],\n",
    "             [1, 2, 3, 4],\n",
    "             [4, 5,6,7]])\n",
    "print(np.einsum(\"ij->\", A))\n",
    "print(np.einsum(\"ij->j\", A))\n",
    "print(np.einsum(\"ij->i\", A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q=np.random.randn(32,64,512)\n",
    "k=np.random.randn(32,128,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 512)\n",
      "(32, 128, 512)\n"
     ]
    }
   ],
   "source": [
    "## Example from transformer paper\n",
    "\n",
    "batchsize = 32   # Example batch size\n",
    "s_q = 64         # Query sequence length\n",
    "s_k = 128         # Key sequence length\n",
    "modelsize = 512   # Model hidden size\n",
    "\n",
    "Q = np.random.rand(batchsize, s_q, modelsize)  # Query tensor\n",
    "K = np.random.rand(batchsize, s_k, modelsize)  # Key tensor\n",
    "\n",
    "print(Q.shape)  # Expected output: (32, 10, 64)\n",
    "print(K.shape)  # Expected output: (32, 15, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 64, 128)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum(\"bqm, bkm -> bqk\", Q,K).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
